{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Title:Skin-Lesion Segmentation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Importing the Libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"from keras.models import Model, Sequential\nfrom keras.layers import Activation, Dense, BatchNormalization, Dropout, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Input, Reshape\nfrom keras import backend as K\nfrom keras.optimizers import Adam\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport glob\nimport PIL\nimport os\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport cv2\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom warnings import filterwarnings\n\nfilterwarnings('ignore')\nplt.rcParams[\"axes.grid\"] = False\nnp.random.seed(101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"print(os.listdir('../input'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The ***PH2 database*** includes\nthe manual segmentation, the clinical diagnosis, and the identification of several dermoscopic\nstructures, performed by expert dermatologists,\n\n\nThe ***PH2 database*** was built up through a joint research collaboration between the Universidade do\nPorto, T ÃÅecnico Lisboa, and the Dermatology service of Hospital Pedro Hispano in Matosinhos,\nPortugal.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Loading the data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"[](http://)Defining a function to load the data in sorted order","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"import re\nnumbers = re.compile(r'(\\d+)')\ndef numericalSort(value):\n    parts = numbers.split(value)\n    parts[1::2] = map(int, parts[1::2])\n    return parts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* * * First we will load the filenames in a list.  ","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"filelist_trainx_ph2 = sorted(glob.glob('../input/*/*/trainx/*.bmp'), key=numericalSort)\nX_train_ph2 = np.array([np.array(Image.open(fname)) for fname in filelist_trainx_ph2])\n\nfilelist_trainy_ph2 = sorted(glob.glob('../input/*/*/trainy/*.bmp'), key=numericalSort)\nY_train_ph2 = np.array([np.array(Image.open(fname)) for fname in filelist_trainy_ph2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\n\nplt.suptitle('Images from PH2 dataset', fontsize = 25, color='blue')\n \nplt.subplot(2,2,1)\nplt.imshow(X_train_ph2[1])\nplt.xlabel(\"Dimensions: \"+str(np.array(X_train_ph2[1]).shape))\nplt.subplot(2,2,2)\nplt.imshow(Y_train_ph2[1], plt.cm.binary_r)\nplt.xlabel(\"Dimensions: \"+str(np.array(Y_train_ph2[1]).shape))\n\nplt.subplot(2,2,3)\nplt.imshow(X_train_ph2[112])\nplt.xlabel(\"Dimensions: \"+str(np.array(X_train_ph2[185]).shape))\nplt.subplot(2,2,4)\nplt.imshow(Y_train_ph2[112], plt.cm.binary_r)\nplt.xlabel(\"Dimensions: \"+str(np.array(Y_train_ph2[185]).shape))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The images are of dimensions **(572, 765)** so we will scale down the images. It will also reduce the training time of the network.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Resizing","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def resize(filename, size = (256,192)):\n    im = Image.open(filename)\n    im_resized = im.resize(size, Image.ANTIALIAS)\n    return (im_resized)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"X_train_ph2_resized = []\nY_train_ph2_resized = []\n\nfor i in range(len(filelist_trainx_ph2)):\n    X_train_ph2_resized.append(resize(filelist_trainx_ph2[i]))\n    Y_train_ph2_resized.append(resize(filelist_trainy_ph2[i]))    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The new resized images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\n\nplt.suptitle('Images from PH2 dataset after Resizing', fontsize = 25, color='blue')\n\nplt.subplot(2,2,1)\nplt.imshow(X_train_ph2_resized[1])\nplt.xlabel(\"Dimensions: \"+str(np.array(X_train_ph2_resized[1]).shape))\nplt.subplot(2,2,2)\nplt.imshow(Y_train_ph2_resized[1], plt.cm.binary_r)\nplt.xlabel(\"Dimensions: \"+str(np.array(Y_train_ph2_resized[1]).shape))\n\nplt.subplot(2,2,3)\nplt.imshow(X_train_ph2_resized[117])\nplt.xlabel(\"Dimensions: \"+str(np.array(X_train_ph2_resized[185]).shape))\nplt.subplot(2,2,4)\nplt.imshow(Y_train_ph2_resized[117], plt.cm.binary_r)\nplt.xlabel(\"Dimensions: \"+str(np.array(Y_train_ph2_resized[185]).shape))\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Converting the transformed Images into numpy arrays","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"X_train_ph2 = np.array([np.array(img) for img in X_train_ph2_resized])\nY_train_ph2 = np.array([np.array(img) for img in Y_train_ph2_resized])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\n\nplt.suptitle('Converting the transformed Image into Numpy Array', fontsize = 25, color='blue')\n\nplt.subplot(1,2,1)\nplt.imshow(X_train_ph2[117])\nplt.xlabel(\"Dimensions: \"+str(np.array(X_train_ph2_resized[180]).shape))\nplt.subplot(1,2,2)\nplt.imshow(Y_train_ph2[117], plt.cm.binary_r)\nplt.xlabel(\"Dimensions: \"+str(np.array(Y_train_ph2_resized[180]).shape))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Splitting the dataset into training set and test set to verify our model performance without any bias.","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(X_train_ph2, Y_train_ph2, test_size = 0.25, random_state = 101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,10))\n\nplt.suptitle('Images from PH2 dataset', fontsize = 30, color='blue')\n\nplt.subplot(3,5,1)\nplt.imshow(X_train_ph2[1])\nplt.subplot(3,5,2)\nplt.imshow(X_train_ph2[12])\nplt.subplot(3,5,3)\nplt.imshow(X_train_ph2[44])\nplt.subplot(3,5,4)\nplt.imshow(X_train_ph2[67])\nplt.subplot(3,5,5)\nplt.imshow(X_train_ph2[100])\nplt.subplot(3,5,6)\nplt.imshow(X_train_ph2[117])\nplt.subplot(3,5,7)\nplt.imshow(X_train_ph2[128])\nplt.subplot(3,5,8)\nplt.imshow(X_train_ph2[147])\nplt.subplot(3,5,9)\nplt.imshow(X_train_ph2[132])\nplt.subplot(3,5,10)\nplt.imshow(X_train_ph2[112])\nplt.subplot(3,5,11)\nplt.imshow(X_train_ph2[31])\nplt.subplot(3,5,12)\nplt.imshow(X_train_ph2[52])\nplt.subplot(3,5,13)\nplt.imshow(X_train_ph2[74])\nplt.subplot(3,5,14)\nplt.imshow(X_train_ph2[86])\nplt.subplot(3,5,15)\nplt.imshow(X_train_ph2[150])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,10))\n\nplt.suptitle('Mask of the corresponding Images from PH2 dataset', fontsize = 30, color='blue')\n\nplt.subplot(3,5,1)\nplt.imshow(Y_train_ph2[1], cmap = plt.cm.binary_r)\nplt.subplot(3,5,2)\nplt.imshow(Y_train_ph2[12], cmap = plt.cm.binary_r)\nplt.subplot(3,5,3)\nplt.imshow(Y_train_ph2[44], cmap = plt.cm.binary_r)\nplt.subplot(3,5,4)\nplt.imshow(Y_train_ph2[67], cmap = plt.cm.binary_r)\nplt.subplot(3,5,5)\nplt.imshow(Y_train_ph2[100], cmap = plt.cm.binary_r)\nplt.subplot(3,5,6)\nplt.imshow(Y_train_ph2[117], cmap = plt.cm.binary_r)\nplt.subplot(3,5,7)\nplt.imshow(Y_train_ph2[128], cmap = plt.cm.binary_r)\nplt.subplot(3,5,8)\nplt.imshow(Y_train_ph2[147], cmap = plt.cm.binary_r)\nplt.subplot(3,5,9)\nplt.imshow(Y_train_ph2[132], cmap = plt.cm.binary_r)\nplt.subplot(3,5,10)\nplt.imshow(Y_train_ph2[112], cmap = plt.cm.binary_r)\nplt.subplot(3,5,11)\nplt.imshow(Y_train_ph2[31], cmap = plt.cm.binary_r)\nplt.subplot(3,5,12)\nplt.imshow(Y_train_ph2[52], cmap = plt.cm.binary_r)\nplt.subplot(3,5,13)\nplt.imshow(Y_train_ph2[74], cmap = plt.cm.binary_r)\nplt.subplot(3,5,14)\nplt.imshow(Y_train_ph2[86], cmap = plt.cm.binary_r)\nplt.subplot(3,5,15)\nplt.imshow(Y_train_ph2[150], cmap = plt.cm.binary_r)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Image Augmentation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Image augmentation artificially creates training images through different ways of processing or combination of multiple processing, such as random rotation, shifts, shear and flips, etc.\n\nTo build a powerful image classifier using little training data, image augmentation is usually required to boost the performance of deep networks.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We are going to define to methods for augmentation, **horizontal flipping** , **vertical flipping** and **random rotation**","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def horizontal_flip(x_image, y_image):\n    x_image = cv2.flip(x_image, 1)\n    y_image = cv2.flip(y_image.astype('float32'), 1)\n    return x_image, y_image.astype('int')\n\ndef vertical_flip(x_image, y_image):\n    x_image = cv2.flip(x_image, 1)\n    y_image = cv2.flip(y_image.astype('float32'), 0)\n    return x_image, y_image.astype('int')\n\ndef random_rotation(x_image, y_image):\n    rows_x,cols_x, chl_x = x_image.shape\n    rows_y,cols_y = y_image.shape\n    rand_num = np.random.randint(-60,60)\n    M1 = cv2.getRotationMatrix2D((cols_x/2,rows_x/2),rand_num,1)\n    M2 = cv2.getRotationMatrix2D((cols_y/2,rows_y/2),rand_num,1)\n    x_image = cv2.warpAffine(x_image,M1,(cols_x,rows_x))\n    y_image = cv2.warpAffine(y_image.astype('float32'),M2,(cols_y,rows_y))\n    return np.array(x_image), np.array(y_image.astype('int'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def img_augmentation(x_train, y_train):\n    x_flip = []\n    y_flip = []\n    x_vert = []\n    y_vert = []\n    x_rotat = []\n    y_rotat = []\n    \n    for idx in range(len(x_train)):\n        \n        x,y = horizontal_flip(x_train[idx], y_train[idx])\n        x_flip.append(x)\n        y_flip.append(y)\n        \n        x,y = vertical_flip(x_train[idx], y_train[idx])\n        x_vert.append(x)\n        y_vert.append(y)\n        \n        x,y = random_rotation(x_train[idx], y_train[idx])\n        x_rotat.append(x)\n        y_rotat.append(y)\n        \n        \n    return  np.array(x_flip), np.array(y_flip), np.array(x_vert), np.array(y_vert), np.array(x_rotat), np.array(y_rotat)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"calling the functions for the training data.","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"x_flipped, y_flipped, x_vertical, y_vertical, x_rotated, y_rotated = img_augmentation(x_train, y_train)\nx_flipped_t, y_flipped_t, x_vertical_t, y_vertical_t, x_rotated_t, y_rotated_t = img_augmentation(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,16))\n\nplt.suptitle('Image Augmentation', fontsize = 25, color='blue')\n\nplt.subplot(4,4,1)\nplt.imshow(x_train[112])\nplt.title('Original Image')\nplt.subplot(4,4,2)\nplt.imshow(y_train[112], plt.cm.binary_r)\nplt.title('Original Mask')\nplt.subplot(4,4,3)\nplt.imshow(x_train[12])\nplt.title('Original Image')\nplt.subplot(4,4,4)\nplt.imshow(y_train[12], plt.cm.binary_r)\nplt.title('Original Mask')\n\nplt.subplot(4,4,5)\nplt.imshow(x_flipped[112])\nplt.title('Horizontal Flipped Image')\nplt.subplot(4,4,6)\nplt.imshow(y_flipped[112], plt.cm.binary_r)\nplt.title('Horizontal Flipped Mask')\nplt.subplot(4,4,7)\nplt.imshow(x_flipped[12])\nplt.title('Horizontal Flipped Image')\nplt.subplot(4,4,8)\nplt.imshow(y_flipped[12], plt.cm.binary_r)\nplt.title('Horizontal Flipped Mask')\n\nplt.subplot(4,4,9)\nplt.imshow(x_vertical[112])\nplt.title('Vertical Flipped Image')\nplt.subplot(4,4,10)\nplt.imshow(y_vertical[112], plt.cm.binary_r)\nplt.title('Vertical Flipped Mask')\nplt.subplot(4,4,11)\nplt.imshow(x_vertical[12])\nplt.title('Vertical Flipped Image')\nplt.subplot(4,4,12)\nplt.imshow(y_vertical[12], plt.cm.binary_r)\nplt.title('Vertical Flipped Mask')\n\nplt.subplot(4,4,13)\nplt.imshow(x_rotated[112])\nplt.title('Rotated Image')\nplt.subplot(4,4,14)\nplt.imshow(y_rotated[112], plt.cm.binary_r)\nplt.title('Rotated Mask')\nplt.subplot(4,4,15)\nplt.imshow(x_rotated[12])\nplt.title('Rotated Image')\nplt.subplot(4,4,16)\nplt.imshow(y_rotated[12], plt.cm.binary_r)\nplt.title('Rotated Mask')\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we join all the augmentations image arrays to the original training arrays.","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# For training Set\nx_train_full = np.concatenate([x_train, x_rotated, x_flipped, x_vertical])\ny_train_full = np.concatenate([y_train, y_rotated, y_flipped, y_vertical])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining Evaluation Metrics","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Intersection over Union(IOU) or Jaccard Index\nThe Jaccard index, also known as Intersection over Union and the Jaccard similarity coefficient is a statistic used for gauging the similarity and diversity of sample sets. The Jaccard coefficient measures similarity between finite sample sets, and is defined as the size of the intersection divided by the size of the union of the sample sets.\n\nJaccard index is popular and frequently used as a similarity index. \nThe area of overlap J is\ncalculated between the segmented binary image A and its ground truth G as shown:\n***J = |A ‚à© G| / |A ‚à™ G| √ó 100%.***","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def iou(y_true, y_pred, smooth = 100):\n    \n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)\n    union = sum_ - intersection\n    jac = (intersection + smooth) / (union + smooth)\n    return jac","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Dice Coefficient\nThe Dice score is not only a measure of how many positives you find, but it also penalizes for the false positives that the method finds, similar to precision. so it is more similar to precision than accuracy.\n\nThe Dice coefficient can be defined as: ***D = 2 |A ‚à© G| / |A + G| √ó 100%*** where A is the algorithm\noutput and G is the ground truth.","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth = 100):\n    \n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Precision\nPrecision is a good measure to determine, when the costs of False Positive is high.\n\n***Precision = true-positive / (true-positive + false-positive)***\n\n Where,True positive is an outcome where the model correctly predicts the positive class and false positive is an outcome where the model incorrectly predicts the positive class.\n \n  '''Precision calculates a metric for multi-label classification of\n    how many selected items are relevant.\n    '''","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def precision(y_true, y_pred):\n   \n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Recall\nRecall actually calculates how many of the Actual Positives our model capture through labeling it as Positive (True Positive). Applying the same understanding, we know that Recall shall be the model metric we use to select our best model when there is a high cost associated with False Negative.\n\n***Recall = true-positive /(true-positive + false negative)***\n\nWhere, true positive is an outcome where the model correctly predicts the positive class and false negative is an outcome where the model incorrectly predicts the negative class.\n\n '''Recall calculates a metric for multi-label classification of\n    how many relevant items are selected.\n    '''","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def recall(y_true, y_pred):\n   \n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Accuracy\n'''Calculates the mean accuracy rate across all predictions for binary\n    classification problems.\n    '''","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def accuracy(y_true, y_pred):\n    \n    return K.mean(K.equal(y_true, K.round(y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining the Loss Function\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Jaccard Distance\n\nThe Jaccard distance measures dissimilarity between sample sets and is complementary to the Jaccard coefficient and is obtained by subtracting the Jaccard coefficient from 1, or, equivalently, by dividing the difference of the sizes of the union and the intersection of two sets by the size of the union.\n\n***Jaccard Distance = 1 - Jaccard Index***","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def jaccard_distance(y_true, y_pred, smooth=100):\n    \n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return (1 - jac)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Making a Validation Set","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size = 0.20, random_state = 101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"print(\"Length of the Training Set   : {}\".format(len(x_train)))\nprint(\"Length of the Test Set       : {}\".format(len(x_test)))\nprint(\"Length of the Validation Set : {}\".format(len(x_val)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will split our full training set into train and validation set.  \nValidation dataset is used to validate the performance after each epoch","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## The Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Defining the model in a function which takes two arguments when called\n\n\n* **epoch_num**: number of epochs to run  \n* **savename**: the name of the model for saving after training  ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Optimizer and Learning Rate  \n\n* We adopt adam optimization algorithm or adaptive moments, to adjust the learning rate.\n* It is well known that learning rate is one of the critical hyperparameters that have a signiÔ¨Åcant impact on classiÔ¨Åcation performance.\n\n### Advantages of Adam optimizer are:\n\n* Relatively low memory requirements (though higher than gradient descent and gradient descent with momentum).\n* Usually works well even with a little tuning of hyperparameter.\n* Adam is fairly robust to the choice of hyperparameters, and set the learning rate Œ± as 0.003 to speed up the training procedure.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Model Function","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* SegNet, a deep convolutional network architecture for semantic segmentation. The main motivation behind SegNet was the need to design an efficient architecture for road and indoor scene understanding which is efficient both in terms of memory and computational time.\n\n* SegNet on the other hand is more efficient since it only stores the max-pooling indices of the feature maps and uses them in its decoder network to achieve good performance.","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def segnet(epochs_num,savename):\n\n    # Encoding layer\n    \n    img_input = Input(shape= (192, 256, 3))\n    x = Conv2D(64, (3, 3), padding='same', name='conv1',strides= (1,1))(img_input)\n    x = BatchNormalization(name='bn1')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(64, (3, 3), padding='same', name='conv2')(x)\n    x = BatchNormalization(name='bn2')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D()(x)\n    \n    x = Conv2D(128, (3, 3), padding='same', name='conv3')(x)\n    x = BatchNormalization(name='bn3')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(128, (3, 3), padding='same', name='conv4')(x)\n    x = BatchNormalization(name='bn4')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D()(x)\n\n    x = Conv2D(256, (3, 3), padding='same', name='conv5')(x)\n    x = BatchNormalization(name='bn5')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(256, (3, 3), padding='same', name='conv6')(x)\n    x = BatchNormalization(name='bn6')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(256, (3, 3), padding='same', name='conv7')(x)\n    x = BatchNormalization(name='bn7')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D()(x)\n\n    x = Conv2D(512, (3, 3), padding='same', name='conv8')(x)\n    x = BatchNormalization(name='bn8')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(512, (3, 3), padding='same', name='conv9')(x)\n    x = BatchNormalization(name='bn9')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(512, (3, 3), padding='same', name='conv10')(x)\n    x = BatchNormalization(name='bn10')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D()(x)\n    \n    x = Conv2D(512, (3, 3), padding='same', name='conv11')(x)\n    x = BatchNormalization(name='bn11')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(512, (3, 3), padding='same', name='conv12')(x)\n    x = BatchNormalization(name='bn12')(x)\n    x = Activation('relu')(x)\n    x = Conv2D(512, (3, 3), padding='same', name='conv13')(x)\n    x = BatchNormalization(name='bn13')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D()(x)\n\n    x = Dense(1024, activation = 'relu', name='fc1')(x)\n    x = Dense(1024, activation = 'relu', name='fc2')(x)\n    \n    # Decoding Layer \n    \n    x = UpSampling2D()(x)\n    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv1')(x)\n    x = BatchNormalization(name='bn14')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv2')(x)\n    x = BatchNormalization(name='bn15')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv3')(x)\n    x = BatchNormalization(name='bn16')(x)\n    x = Activation('relu')(x)\n    \n    x = UpSampling2D()(x)\n    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv4')(x)\n    x = BatchNormalization(name='bn17')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(512, (3, 3), padding='same', name='deconv5')(x)\n    x = BatchNormalization(name='bn18')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv6')(x)\n    x = BatchNormalization(name='bn19')(x)\n    x = Activation('relu')(x)\n\n    x = UpSampling2D()(x)\n    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv7')(x)\n    x = BatchNormalization(name='bn20')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv8')(x)\n    x = BatchNormalization(name='bn21')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv9')(x)\n    x = BatchNormalization(name='bn22')(x)\n    x = Activation('relu')(x)\n\n    x = UpSampling2D()(x)\n    x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv10')(x)\n    x = BatchNormalization(name='bn23')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(64, (3, 3), padding='same', name='deconv11')(x)\n    x = BatchNormalization(name='bn24')(x)\n    x = Activation('relu')(x)\n    \n    x = UpSampling2D()(x)\n    x = Conv2DTranspose(64, (3, 3), padding='same', name='deconv12')(x)\n    x = BatchNormalization(name='bn25')(x)\n    x = Activation('relu')(x)\n    x = Conv2DTranspose(1, (3, 3), padding='same', name='deconv13')(x)\n    x = BatchNormalization(name='bn26')(x)\n    x = Activation('softmax')(x)\n    pred = Reshape((192,256))(x)\n    \n    \n    model = Model(inputs=img_input, outputs=pred)\n     \n    model.compile(optimizer= Adam(lr = 0.003), loss= [jaccard_distance]\n                  , metrics=[iou, dice_coef, precision, recall, accuracy])\n    \n    model.summary()\n    hist = model.fit(x_train, y_train, epochs= epochs_num, batch_size= 32, validation_data= (x_val, y_val), verbose=1)\n    \n    model.save(savename)\n    return model,hist","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading the Model","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Encoding layer\n\nimg_input = Input(shape= (192, 256, 3))\nx = Conv2D(64, (3, 3), padding='same', name='conv1',strides= (1,1))(img_input)\nx = BatchNormalization(name='bn1')(x)\nx = Activation('relu')(x)\nx = Conv2D(64, (3, 3), padding='same', name='conv2')(x)\nx = BatchNormalization(name='bn2')(x)\nx = Activation('relu')(x)\nx = MaxPooling2D()(x)\n\nx = Conv2D(128, (3, 3), padding='same', name='conv3')(x)\nx = BatchNormalization(name='bn3')(x)\nx = Activation('relu')(x)\nx = Conv2D(128, (3, 3), padding='same', name='conv4')(x)\nx = BatchNormalization(name='bn4')(x)\nx = Activation('relu')(x)\nx = MaxPooling2D()(x)\n\nx = Conv2D(256, (3, 3), padding='same', name='conv5')(x)\nx = BatchNormalization(name='bn5')(x)\nx = Activation('relu')(x)\nx = Conv2D(256, (3, 3), padding='same', name='conv6')(x)\nx = BatchNormalization(name='bn6')(x)\nx = Activation('relu')(x)\nx = Conv2D(256, (3, 3), padding='same', name='conv7')(x)\nx = BatchNormalization(name='bn7')(x)\nx = Activation('relu')(x)\nx = MaxPooling2D()(x)\n\nx = Conv2D(512, (3, 3), padding='same', name='conv8')(x)\nx = BatchNormalization(name='bn8')(x)\nx = Activation('relu')(x)\nx = Conv2D(512, (3, 3), padding='same', name='conv9')(x)\nx = BatchNormalization(name='bn9')(x)\nx = Activation('relu')(x)\nx = Conv2D(512, (3, 3), padding='same', name='conv10')(x)\nx = BatchNormalization(name='bn10')(x)\nx = Activation('relu')(x)\nx = MaxPooling2D()(x)\n\nx = Conv2D(512, (3, 3), padding='same', name='conv11')(x)\nx = BatchNormalization(name='bn11')(x)\nx = Activation('relu')(x)\nx = Conv2D(512, (3, 3), padding='same', name='conv12')(x)\nx = BatchNormalization(name='bn12')(x)\nx = Activation('relu')(x)\nx = Conv2D(512, (3, 3), padding='same', name='conv13')(x)\nx = BatchNormalization(name='bn13')(x)\nx = Activation('relu')(x)\nx = MaxPooling2D()(x)\n\nx = Dense(1024, activation = 'relu', name='fc1')(x)\nx = Dense(1024, activation = 'relu', name='fc2')(x)\n\n# Decoding Layer \n\nx = UpSampling2D()(x)\nx = Conv2DTranspose(512, (3, 3), padding='same', name='deconv1')(x)\nx = BatchNormalization(name='bn14')(x)\nx = Activation('relu')(x)\nx = Conv2DTranspose(512, (3, 3), padding='same', name='deconv2')(x)\nx = BatchNormalization(name='bn15')(x)\nx = Activation('relu')(x)\nx = Conv2DTranspose(512, (3, 3), padding='same', name='deconv3')(x)\nx = BatchNormalization(name='bn16')(x)\nx = Activation('relu')(x)\n\nx = UpSampling2D()(x)\nx = Conv2DTranspose(512, (3, 3), padding='same', name='deconv4')(x)\nx = BatchNormalization(name='bn17')(x)\nx = Activation('relu')(x)\nx = Conv2DTranspose(512, (3, 3), padding='same', name='deconv5')(x)\nx = BatchNormalization(name='bn18')(x)\nx = Activation('relu')(x)\nx = Conv2DTranspose(256, (3, 3), padding='same', name='deconv6')(x)\nx = BatchNormalization(name='bn19')(x)\nx = Activation('relu')(x)\n\nx = UpSampling2D()(x)\nx = Conv2DTranspose(256, (3, 3), padding='same', name='deconv7')(x)\nx = BatchNormalization(name='bn20')(x)\nx = Activation('relu')(x)\nx = Conv2DTranspose(256, (3, 3), padding='same', name='deconv8')(x)\nx = BatchNormalization(name='bn21')(x)\nx = Activation('relu')(x)\nx = Conv2DTranspose(128, (3, 3), padding='same', name='deconv9')(x)\nx = BatchNormalization(name='bn22')(x)\nx = Activation('relu')(x)\n\nx = UpSampling2D()(x)\nx = Conv2DTranspose(128, (3, 3), padding='same', name='deconv10')(x)\nx = BatchNormalization(name='bn23')(x)\nx = Activation('relu')(x)\nx = Conv2DTranspose(64, (3, 3), padding='same', name='deconv11')(x)\nx = BatchNormalization(name='bn24')(x)\nx = Activation('relu')(x)\n\nx = UpSampling2D()(x)\nx = Conv2DTranspose(64, (3, 3), padding='same', name='deconv12')(x)\nx = BatchNormalization(name='bn25')(x)\nx = Activation('relu')(x)\nx = Conv2DTranspose(1, (3, 3), padding='same', name='deconv13')(x)\nx = BatchNormalization(name='bn26')(x)\nx = Activation('softmax')(x)\npred = Reshape((192,256))(x)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> #### After 120 epochs","execution_count":null},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"model, hist = segnet(epochs_num= 120, savename= 'segnet_120_epoch.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"model_1 = Model(inputs=img_input, outputs=pred)\nmodel_1.compile(optimizer= Adam(lr = 0.003), loss= [jaccard_distance]\n              , metrics=[iou, dice_coef, precision, recall, accuracy])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"model_1.load_weights('segnet_120_epoch.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\n~~~~~~~~~~~~~~~Stats after 120 epoch~~~~~~~~~~~~~~~~~~~')\nprint('\\n------------------On Train Set-----------------------------\\n')\nres = model_1.evaluate(x_train, y_train, batch_size = 48)\nprint('________________________')\nprint('IOU:       |   {:.2f}  |'.format(res[1]*100))\nprint('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\nprint('Precision: |   {:.2f}  |'.format(res[3]*100))\nprint('Recall:    |   {:.2f}  |'.format(res[4]*100))\nprint('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\nprint(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\nprint('________________________')\nprint('\\n-----------------On Test  Set-----------------------------\\n')\nres = model_1.evaluate(x_test, y_test, batch_size = 48)\nprint('________________________')\nprint('IOU:       |   {:.2f}  |'.format(res[1]*100))\nprint('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\nprint('Precision: |   {:.2f}  |'.format(res[3]*100))\nprint('Recall:    |   {:.2f}  |'.format(res[4]*100))\nprint('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\nprint(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\nprint('________________________')\nprint('\\n----------------On validation Set-----------------------------\\n')\nres = model_1.evaluate(x_val, y_val, batch_size = 48)\nprint('________________________')\nprint('IOU:       |   {:.2f}  |'.format(res[1]*100))\nprint('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\nprint('Precision: |   {:.2f}  |'.format(res[3]*100))\nprint('Recall:    |   {:.2f}  |'.format(res[4]*100))\nprint('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\nprint(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\nprint('________________________')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting Training Statistics","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24, 14))\n\nplt.suptitle('Training Statistics on Train Set', fontsize = 30, color='blue')\n\nplt.subplot(2,2,1)\nplt.plot(hist.history['loss'], 'red')\nplt.title('Loss',fontsize = 18, color='blue')\nplt.subplot(2,2,2)\nplt.plot(hist.history['accuracy'], 'green')\nplt.title('Accuracy',fontsize = 18, color='blue')\nplt.subplot(2,2,3)\nplt.plot(hist.history['val_loss'], 'red')\nplt.yticks(list(np.arange(0.0, 1.0, 0.10)))\nplt.title('Valdiation Loss',fontsize = 18, color='blue')\nplt.subplot(2,2,4)\nplt.plot(hist.history['val_accuracy'], 'green')\nplt.yticks(list(np.arange(0.0, 1.0, 0.10)))\nplt.title('Validation Accuracy',fontsize = 18, color='blue')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualising Predicted Lesions","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We have trained the model on the **training set**.  \nWe will make predictions on the unseen **test set**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,16))\n\nplt.suptitle('Visualising Predicted Lesions', fontsize = 30, color='blue')\n\nimg_pred = model_1.predict(x_test[49].reshape(1,192,256,3))\nplt.subplot(4,3,1)\nplt.imshow(x_test[49])\nplt.title('Original Image')\nplt.subplot(4,3,2)\nplt.imshow(y_test[49], plt.cm.binary_r)\nplt.title('True Mask')\nplt.subplot(4,3,3)\nplt.imshow(img_pred.reshape(192, 256), plt.cm.binary_r)\nplt.title('Predicted Mask')\n\nimg_pred = model_1.predict(x_test[36].reshape(1,192,256,3))\nplt.subplot(4,3,4)\nplt.imshow(x_test[36])\nplt.title('Original Image')\nplt.subplot(4,3,5)\nplt.imshow(y_test[36], plt.cm.binary_r)\nplt.title('True Mask')\nplt.subplot(4,3,6)\nplt.imshow(img_pred.reshape(192, 256), plt.cm.binary_r)\nplt.title('Predicted Mask')\n\nimg_pred = model_1.predict(x_test[32].reshape(1,192,256,3))\nplt.subplot(4,3,7)\nplt.imshow(x_test[32])\nplt.title('Original Image')\nplt.subplot(4,3,8)\nplt.imshow(y_test[32], plt.cm.binary_r)\nplt.title('True Mask')\nplt.subplot(4,3,9)\nplt.imshow(img_pred.reshape(192, 256), plt.cm.binary_r)\nplt.title('Predicted Mask')\n\nimg_pred = model_1.predict(x_test[21].reshape(1,192,256,3))\nplt.subplot(4,3,10)\nplt.imshow(x_test[21])\nplt.title('Original Image')\nplt.subplot(4,3,11)\nplt.imshow(y_test[21], plt.cm.binary_r)\nplt.title('True Mask')\nplt.subplot(4,3,12)\nplt.imshow(img_pred.reshape(192, 256), plt.cm.binary_r)\nplt.title('Predicted Mask')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Final Enhance","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Currently the predicted outputs are blurry because the predicted pixel values are in the range 0 - 1.\n* To make clear edge preditions we can enhance our image by rounding up the pixel values to 1 which are > 0.5 .\n* While rounding down the pixel values to 0 which are < 0.5.\n* We can enhance the image to look for absolute shape predicted by ceiling and flooring the predicted values","execution_count":null},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def enhance(img):\n    sub = (model_1.predict(img.reshape(1,192,256,3))).flatten()\n\n    for i in range(len(sub)):\n        if sub[i] > 0.5:\n            sub[i] = 1\n        else:\n            sub[i] = 0\n    return sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24,16))\n\nplt.suptitle('Comparing the Prediction after Enhancement', fontsize = 30, color='blue')\n\nplt.subplot(4,3,1)\nplt.imshow(x_test[21])\nplt.title('Original Image')\nplt.subplot(4,3,2)\nplt.imshow(y_test[21],plt.cm.binary_r)\nplt.title('True Mask')\nplt.subplot(4,3,3)\nplt.imshow(enhance(x_test[21]).reshape(192,256), plt.cm.binary_r)\nplt.title('Predicted after threshold')\n\nplt.subplot(4,3,4)\nplt.imshow(x_test[19])\nplt.title('Original Image')\nplt.subplot(4,3,5)\nplt.imshow(y_test[19],plt.cm.binary_r)\nplt.title('True Mask')\nplt.subplot(4,3,6)\nplt.imshow(enhance(x_test[19]).reshape(192,256), plt.cm.binary_r)\nplt.title('Predicted after threshold')\n\nplt.subplot(4,3,7)\nplt.imshow(x_test[36])\nplt.title('Original Image')\nplt.subplot(4,3,8)\nplt.imshow(y_test[36],plt.cm.binary_r)\nplt.title('True Mask')\nplt.subplot(4,3,9)\nplt.imshow(enhance(x_test[36]).reshape(192,256), plt.cm.binary_r)\nplt.title('Predicted after threshold')\n\n\nplt.subplot(4,3,10)\nplt.imshow(x_test[49])\nplt.title('Original Image')\nplt.subplot(4,3,11)\nplt.imshow(y_test[49],plt.cm.binary_r)\nplt.title('True Mask')\nplt.subplot(4,3,12)\nplt.imshow(enhance(x_test[49]).reshape(192,256), plt.cm.binary_r)\nplt.title('Predicted after threshold')\n\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}